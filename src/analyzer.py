#!/usr/bin/env python3
"""
–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–† –ü–°–ï–í–î–û–ö–û–î–ê
–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑,
–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ AST –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.
"""

import os
import sys
import json
from typing import List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.lexer import PseudocodeLexer, LexerAnalyzer
from src.parser import Parser, ASTValidator, ASTNode


class PseudocodeAnalyzer:
    """
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Å–µ–≤–¥–æ–∫–æ–¥–∞.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã –∞–Ω–∞–ª–∏–∑–∞:
    1. –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    2. –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑  
    3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ AST
    4. –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        self.lexer_analyzer = LexerAnalyzer()
        self.ast_validator = ASTValidator()
        self.tokens = []
        self.ast = None
        self.validation_errors = []
    
    def analyze(self, code: str) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞.
        
        Args:
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –Ω–∞ –ø—Å–µ–≤–¥–æ–∫–æ–¥–µ
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            # –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            self.tokens = self.lexer_analyzer.analyze(code)
            
            if not self.tokens:
                return {
                    'success': False,
                    'errors': ['–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'],
                    'tokens': [],
                    'ast': None
                }
            
            # –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ AST
            parser = Parser(self.tokens)
            self.ast = parser.parse()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è AST
            self.validation_errors = self.ast_validator.validate(self.ast)
            
            return {
                'success': len(self.validation_errors) == 0,
                'errors': self.validation_errors,
                'tokens': self.tokens,
                'ast': self.ast,
                'token_count': len(self.tokens),
                'ast_json': self.ast.to_dict() if self.ast else None
            }
            
        except Exception as e:
            return {
                'success': False,
                'errors': [f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"],
                'tokens': self.tokens,
                'ast': None,
                'token_count': len(self.tokens),
                'ast_json': None
            }
    
    def analyze_file(self, file_path: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥ –∏–∑ —Ñ–∞–π–ª–∞.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∫–æ–¥–æ–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            return self.analyze(code)
        except FileNotFoundError:
            return {
                'success': False,
                'errors': [f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}"],
                'tokens': [],
                'ast': None
            }
        except Exception as e:
            return {
                'success': False,
                'errors': [f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}"],
                'tokens': [],
                'ast': None
            }
    
    def print_ast(self, node: ASTNode, level: int = 0):
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤—ã–≤–æ–¥–∏—Ç AST –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
        
        Args:
            node: –£–∑–µ–ª AST –¥–ª—è –≤—ã–≤–æ–¥–∞
            level: –¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
        """
        indent = "  " * level
        node_info = f"{node.node_type.value}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —É–∑–ª–æ–≤
        if node.node_type.value == 'VARIABLE':
            node_info += f"({node.name})"
        elif node.node_type.value == 'NUMBER':
            node_info += f"({node.value})"
        elif node.node_type.value == 'STRING':
            node_info += f"('{node.value}')"
        elif node.node_type.value == 'ASSIGNMENT':
            node_info += f"({node.variable.name})"
        elif node.node_type.value == 'BINARY_OP':
            node_info += f"({node.operator})"
        elif node.node_type.value == 'ARRAY':
            node_info += f"[{len(node.elements) if hasattr(node, 'elements') else 0} elements]"
        elif node.node_type.value == 'ARRAY_ACCESS':
            node_info += f"(access)"
        
        print(f"{indent}‚îú‚îÄ {node_info}")
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –¥–æ—á–µ—Ä–Ω–∏–µ —É–∑–ª—ã
        for attr_name in dir(node):
            if not attr_name.startswith('_') and attr_name not in ['node_type', 'line', 'column']:
                attr_value = getattr(node, attr_name)
                
                if isinstance(attr_value, ASTNode):
                    print(f"{indent}‚îÇ  ‚îî‚îÄ {attr_name}:")
                    self.print_ast(attr_value, level + 2)
                elif isinstance(attr_value, list) and attr_value:
                    print(f"{indent}‚îÇ  ‚îî‚îÄ {attr_name}:")
                    for i, item in enumerate(attr_value):
                        if isinstance(item, ASTNode):
                            print(f"{indent}‚îÇ     [{i}]:")
                            self.print_ast(item, level + 3)
                        else:
                            print(f"{indent}‚îÇ     [{i}]: {item}")
    
    def print_analysis_report(self, result: Dict[str, Any], title: str = "–ê–ù–ê–õ–ò–ó –ü–°–ï–í–î–û–ö–û–î–ê"):
        """
        –í—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞.
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
        """
        print("=" * 80)
        print(title)
        print("=" * 80)
        
        # –°—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞
        if result['success']:
            print("‚úÖ –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ï–ù")
        else:
            print("‚ùå –û–ë–ù–ê–†–£–ñ–ï–ù–´ –û–®–ò–ë–ö–ò")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∞—Ö
        print(f"\nüìä –õ–ï–ö–°–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó:")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result['token_count']}")
        
        # –û—à–∏–±–∫–∏
        if result['errors']:
            print(f"\nüö® –û–®–ò–ë–ö–ò –í–ê–õ–ò–î–ê–¶–ò–ò:")
            for error in result['errors']:
                print(f"   ‚Ä¢ {error}")
        
        # AST
        if result['ast']:
            print(f"\nüå≥ –ê–ë–°–¢–†–ê–ö–¢–ù–û–ï –°–ò–ù–¢–ê–ö–°–ò–ß–ï–°–ö–û–ï –î–ï–†–ï–í–û (AST):")
            self.print_ast(result['ast'])
        
        # JSON –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        if result.get('ast_json'):
            print(f"\nüìÑ JSON –ü–†–ï–î–°–¢–ê–í–õ–ï–ù–ò–ï AST:")
            print(json.dumps(result['ast_json'], indent=2, ensure_ascii=False))
    
    def export_ast_json(self, file_path: str):
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç AST –≤ JSON —Ñ–∞–π–ª.
        
        Args:
            file_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON
        """
        if self.ast:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(self.ast.to_dict(), f, indent=2, ensure_ascii=False)
                print(f"‚úÖ AST —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤: {file_path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        else:
            print("‚ùå –ù–µ—Ç AST –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")


def demonstrate_parser_capabilities():
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
    """
    print("üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ò–ù–¢–ê–ö–°–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
    print("=" * 60)
    
    test_cases = [
        {
            'name': '–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞',
            'code': """
x = 10;
y = x + 5;
print("Result: " + y);
"""
        },
        {
            'name': '–£—Å–ª–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã',
            'code': """
if (x > 5) {
    print("x is large");
} else {
    print("x is small");
}
"""
        },
        {
            'name': '–¶–∏–∫–ª—ã',
            'code': """
for i in range(1, 5) {
    print("Number: " + i);
}

counter = 3;
while (counter > 0) {
    print("Counter: " + counter);
    counter = counter - 1;
}
"""
        },
        {
            'name': '–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞',
            'code': """
# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—É–º–º—ã —á–µ—Ç–Ω—ã—Ö —á–∏—Å–µ–ª
sum = 0;
n = 10;

for i in range(1, n + 1) {
    if (i % 2 == 0) {
        sum = sum + i;
        print("Added: " + i);
    }
}

print("Total sum: " + sum);
"""
        }
    ]
    
    analyzer = PseudocodeAnalyzer()
    
    for test_case in test_cases:
        print(f"\nüîπ {test_case['name']}:")
        print("-" * 40)
        result = analyzer.analyze(test_case['code'])
        
        if result['success']:
            print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ! –¢–æ–∫–µ–Ω–æ–≤: {result['token_count']}")
        else:
            print(f"   ‚ùå –û—à–∏–±–∫–∏: {len(result['errors'])}")
            for error in result['errors']:
                print(f"      ‚Ä¢ {error}")


def analyze_example_files():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ñ–∞–π–ª–æ–≤.
    """
    print("\nüìÅ –ê–ù–ê–õ–ò–ó –ü–†–ò–ú–ï–†–û–í –ò–ó –§–ê–ô–õ–û–í")
    print("=" * 60)
    
    analyzer = PseudocodeAnalyzer()
    test_files = [
        'tests/test_cases/basic.pseudo',
        'tests/test_cases/arithmetic.pseudo',
        'tests/test_cases/loops.pseudo',
        'examples/factorial.pseudo',
        'examples/max_finder.pseudo'
    ]
    
    for file_path in test_files:
        full_path = os.path.join(os.path.dirname(__file__), '..', file_path)
        
        if os.path.exists(full_path):
            print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}")
            result = analyzer.analyze_file(full_path)
            
            if result['success']:
                print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ! –¢–æ–∫–µ–Ω–æ–≤: {result['token_count']}")
                # –ö—Ä–∞—Ç–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± AST
                if result['ast']:
                    statements_count = len(result['ast'].statements) if hasattr(result['ast'], 'statements') else 0
                    print(f"   üå≥ AST —É–∑–ª–æ–≤: {statements_count} –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∏: {len(result['errors'])}")
                for error in result['errors']:
                    print(f"      ‚Ä¢ {error}")
        else:
            print(f"   ‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {full_path}")


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
    """
    print("üéØ –°–ò–ù–¢–ê–ö–°–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–† –ü–°–ï–í–î–û–ö–û–î–ê - –õ–†2")
    print("=" * 60)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    demonstrate_parser_capabilities()
    
    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤
    analyze_example_files()
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–∞
    print("\n" + "=" * 60)
    print("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–†–ò–ú–ï–†–ê")
    print("=" * 60)
    
    example_code = """
# –ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ—Ä–∏–∞–ª–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
n = 5;
factorial = 1;

print("Calculating factorial of " + n);

if (n > 0) {
    for i in range(1, n + 1) {
        factorial = factorial * i;
        print("Step " + i + ": factorial = " + factorial);
    }
    print("Result: " + n + "! = " + factorial);
} else if (n == 0) {
    print("0! = 1");
} else {
    print("Cannot calculate factorial of negative number");
}
"""

    analyzer = PseudocodeAnalyzer()
    result = analyzer.analyze(example_code)
    analyzer.print_analysis_report(result, "–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ì–†–ê–ú–ú–´")
    
    # –≠–∫—Å–ø–æ—Ä—Ç AST (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # analyzer.export_ast_json("ast_export.json")
    
    print("\n" + "=" * 60)
    if result['success']:
        print("‚úÖ –°–ò–ù–¢–ê–ö–°–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–† –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û!")
    else:
        print("‚ùå –¢–†–ï–ë–£–Æ–¢–°–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
    print("=" * 60)


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print(f"\nüí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()